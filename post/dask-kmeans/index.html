<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.81.0"><title>Speeding up some K-means computation with dask &#183; Chris Havlin</title><meta name=description content><meta itemprop=name content="Speeding up some K-means computation with dask"><meta itemprop=description content="I recently dusted off a manuscript that&rsquo;s been in the works for quite some time now related to seismic observations in the Western United States."><meta itemprop=datePublished content="2021-05-06T11:47:10-05:00"><meta itemprop=dateModified content="2021-05-06T11:47:10-05:00"><meta itemprop=wordCount content="1073"><meta itemprop=image content="https://chrishavlin.github.io/images/turt.png"><meta itemprop=keywords content><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://chrishavlin.github.io/images/turt.png"><meta name=twitter:title content="Speeding up some K-means computation with dask"><meta name=twitter:description content="I recently dusted off a manuscript that&rsquo;s been in the works for quite some time now related to seismic observations in the Western United States."><meta property="og:title" content="Speeding up some K-means computation with dask"><meta property="og:description" content="I recently dusted off a manuscript that&rsquo;s been in the works for quite some time now related to seismic observations in the Western United States."><meta property="og:type" content="article"><meta property="og:url" content="https://chrishavlin.github.io/post/dask-kmeans/"><meta property="og:image" content="https://chrishavlin.github.io/images/turt.png"><meta property="article:section" content="post"><meta property="article:published_time" content="2021-05-06T11:47:10-05:00"><meta property="article:modified_time" content="2021-05-06T11:47:10-05:00"><meta property="og:site_name" content="Chris Havlin"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Person","@id":"https://chrishavlin.github.io/#author","name":null,"image":{"@type":"ImageObject","url":"https://chrishavlin.github.io/images/turt.png"},"description":" "},{"@type":"WebSite","@id":"https://chrishavlin.github.io/#website","url":"https://chrishavlin.github.io/","name":"Chris Havlin","description":" ","publisher":{"@id":"https://chrishavlin.github.io/#author"},"inLanguage":"en"},{"@type":"ImageObject","url":"https://chrishavlin.github.io/images/turt.png","caption":"Chris Havlin"},{"@type":"WebPage","@id":"https://chrishavlin.github.io/post/dask-kmeans/#webpage","url":"https://chrishavlin.github.io/post/dask-kmeans/","name":"Speeding up some K-means computation with dask","isPartOf":{"@id":"https://chrishavlin.github.io/#website"},"about":{"@id":"https://chrishavlin.github.io/#author"},"datePublished":"2021-05-06T11:47:10-05:00","dateModified":"2021-05-06T11:47:10-05:00","description":"I recently dusted off a manuscript that\u0026rsquo;s been in the works for quite some time now related to seismic observations in the Western United States.","inLanguage":"en","potentialAction":[{"@type":"ReadAction","target":["https://chrishavlin.github.io/post/dask-kmeans/"]}]},{"@type":"Article","isPartOf":{"@id":"https://chrishavlin.github.io/post/dask-kmeans/#webpage"},"mainEntityOfPage":{"@id":"https://chrishavlin.github.io/post/dask-kmeans/#webpage"},"headline":"Speeding up some K-means computation with dask","datePublished":"2021-05-06T11:47:10-05:00","dateModified":"2021-05-06T11:47:10-05:00","publisher":{"@id":"https://chrishavlin.github.io/#author"},"keywords":[],"articleSection":[],"inLanguage":"en","author":{"@type":"Person","name":null},"potentialAction":[{"@type":"CommentAction","name":"Comment","target":["https://chrishavlin.github.io/post/dask-kmeans/#comments"]}]}]}</script><link type=text/css rel=stylesheet href=/css/print.css media=print><link type=text/css rel=stylesheet href=/css/poole.css><link type=text/css rel=stylesheet href=/css/hyde.css><style type=text/css>.sidebar{background-color:#3b7044}.read-more-link a{border-color:#3b7044}.read-more-link a:hover{background-color:#3b7044}.pagination li a{color:#3b7044;border:1px solid #3b7044}.pagination li.active a{background-color:#3b7044}.pagination li a:hover{background-color:#3b7044;opacity:.75}footer a,.content a,.related-posts li a:hover{color:#3b7044}</style><link type=text/css rel=stylesheet href=/css/blog.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700&display=swap"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin=anonymous><link rel=apple-touch-icon-precomposed sizes=144x144 href=/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=/favicon.png></head><body><aside class=sidebar><div class=container><div class=sidebar-about><div class=author-image><a href=https://chrishavlin.github.io/><img src=/images/turt.png class="img-circle img-headshot center" alt="Profile Picture"></a></div><h1>Chris Havlin</h1><p class=lead></p></div><nav><ul class=sidebar-nav><li><a href=https://chrishavlin.github.io/>Home</a></li><li><a href=/about/>About</a></li><li><a href=/posts/>Posts</a></li><li><a href=/categories/>Categories</a></li><li><a href=/tags/>Tags</a></li></ul></nav><section class=social-icons><a href=https://github.com/chrishavlin rel=me title=GitHub target=_blank><i class="fab fa-github" aria-hidden=true></i></a><a href=https://twitter.com/s_i_r_h_c rel=me title=@s_i_r_h_c target=_blank><i class="fab fa-twitter" aria-hidden=true></i></a><a href=https://www.instagram.com/chrishavlin/ rel=me title=@chrishavlin target=_blank><i class="fab fa-instagram" aria-hidden=true></i></a><a href=https://www.linkedin.com/in/christopherhavlin/ rel=me title=Linkedin target=_blank><i class="fab fa-linkedin" aria-hidden=true></i></a></section></div></aside><main class="content container"><div class=post><h1 class=title>Speeding up some K-means computation with dask</h1><div class=post-date><time datetime=2021-05-06T11:47:10-0500>May 6, 2021</time> <span class=readtime>&#183; 6 min read</span></div><div><p>I recently dusted off a manuscript that&rsquo;s been in the works for quite some time now related to seismic observations in the Western United States. Part of this work includes some K-means clustering analysis that I wasn&rsquo;t quite happy with and so I started re-working it a bit. In doing so, I decided to use the <code>TimeSeriesKMeans</code> method from the <a href=https://tslearn.readthedocs.io/en/stable/>tslearn</a> package to classify a set of 1D profiles and ended up leveraging <a href=https://docs.dask.org/en/latest/delayed.html>dask.delayed</a> to speed things up a bit. It turned out to be very simple but could be useful to others out there looking to speed up their kmeans analysis. So here&rsquo;s a quick write-up!</p><h2 id=initial-data-and-modeling>Initial data and modeling</h2><p>I won&rsquo;t be going into much detail here on the data here, but in a few short words, I&rsquo;m using a seismic tomography model that measures perturbations in seismic shear wave velocity in the Western US. This is a 3D model, and I was interested in classifying depth variations in velocity perturbation (as opposed to classifying scalar values at a single depth).</p><p>Just 3 of these profiles look like this (x-axis is velocity perturbation, y-axis is depth below the earth&rsquo;s surface):</p><p><img src=/images/DasKmeans_files/DasKmeans_3_1.png alt=png></p><p>Ok, but we have a lot more than 3&mldr; our data array, <code>dvsN</code>:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>dvsN<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]
</code></pre></div><p>has 11,346 profiles. In order to classify my profiles, we can leverage the <code>TimeSeriesKMeans</code> class from <code>tslearn</code>. Even though we don&rsquo;t have a timeseries, the algorithm doesn&rsquo;t require &ldquo;time&rdquo;, just an array of data of shape <code>(number of measurements, number of points for each measurement)</code>. So first we import:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> tslearn.clustering <span style=color:#f92672>import</span> TimeSeriesKMeans
</code></pre></div><p>and then we instantiate a model and then fit to our data:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>%%</span>time
model <span style=color:#f92672>=</span> TimeSeriesKMeans(n_clusters<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, metric<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;euclidean&#34;</span>, max_iter<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)
model<span style=color:#f92672>.</span>fit(dvsN)
</code></pre></div><p>I actually found this method while reading this great <a href=https://towardsdatascience.com/how-to-apply-k-means-clustering-to-time-series-data-28d04a8f7da3>writeup on Dynamic Time Warping</a>, but I&rsquo;m just using a standard <code>euclidean</code> metric here (as it&rsquo;s faster and actually seems to work better for my data). In any case,
we can pull out each cluster&rsquo;s center profiles along with the curves belonging to each category as follows:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>clrs <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;k&#39;</span>, <span style=color:#e6db74>&#39;b&#39;</span>, <span style=color:#e6db74>&#39;r&#39;</span>]
<span style=color:#66d9ef>for</span> iclust <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>3</span>):
    members <span style=color:#f92672>=</span> dvsN[model<span style=color:#f92672>.</span>labels_<span style=color:#f92672>==</span>iclust,:]<span style=color:#f92672>.</span>T
    plt<span style=color:#f92672>.</span>plot(members, depth, color<span style=color:#f92672>=</span>clrs[iclust], alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>)    
    
<span style=color:#66d9ef>for</span> iclust <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>3</span>):
    members <span style=color:#f92672>=</span> dvsN[model<span style=color:#f92672>.</span>labels_<span style=color:#f92672>==</span>iclust,:]<span style=color:#f92672>.</span>T        
    plt<span style=color:#f92672>.</span>plot(model<span style=color:#f92672>.</span>cluster_centers_[iclust,:], depth, marker<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;.&#39;</span>, color<span style=color:#f92672>=</span>clrs[iclust])
    plt<span style=color:#f92672>.</span>plot(model<span style=color:#f92672>.</span>cluster_centers_[iclust,:], depth, marker<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;.&#39;</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;g&#39;</span>, linewidth<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
    
plt<span style=color:#f92672>.</span>gca()<span style=color:#f92672>.</span>invert_yaxis()
plt<span style=color:#f92672>.</span>gca()<span style=color:#f92672>.</span>set_xlim([<span style=color:#f92672>-</span><span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>8</span>])
</code></pre></div><p><img src=/images/DasKmeans_files/DasKmeans_6_1.png alt=png></p><p>And we see our data splits into a slow (negative, black), neutral (close to 0, red) and fast (blue) categories. But there is obviously quite a lot of scatter in each category, so let&rsquo;s re-calculate with more clusters:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>%%</span>time
model <span style=color:#f92672>=</span> TimeSeriesKMeans(n_clusters<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>, metric<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;euclidean&#34;</span>, max_iter<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)
model<span style=color:#f92672>.</span>fit(dvsN)
</code></pre></div><p>And plot again (now using a non-sequential categorical colormap):</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> matplotlib.cm <span style=color:#f92672>import</span> get_cmap
cmap <span style=color:#f92672>=</span> get_cmap(<span style=color:#e6db74>&#39;Paired&#39;</span>)

fig<span style=color:#f92672>=</span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>9</span>,<span style=color:#ae81ff>5</span>), dpi<span style=color:#f92672>=</span> <span style=color:#ae81ff>100</span>, facecolor<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;w&#39;</span>, edgecolor<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;k&#39;</span>)

<span style=color:#66d9ef>for</span> iclust <span style=color:#f92672>in</span> range(model<span style=color:#f92672>.</span>n_clusters):    
    members <span style=color:#f92672>=</span> dvsN[model<span style=color:#f92672>.</span>labels_<span style=color:#f92672>==</span>iclust,:]<span style=color:#f92672>.</span>T
    rgba <span style=color:#f92672>=</span> cmap(iclust <span style=color:#f92672>/</span> (model<span style=color:#f92672>.</span>n_clusters<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>))
    rgb_curves <span style=color:#f92672>=</span> rgba[<span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>3</span>] <span style=color:#f92672>+</span> (<span style=color:#ae81ff>0.01</span>, )
    plt<span style=color:#f92672>.</span>plot(members, depth, color<span style=color:#f92672>=</span>rgb_curves)        
    
<span style=color:#66d9ef>for</span> iclust <span style=color:#f92672>in</span> range(model<span style=color:#f92672>.</span>n_clusters):    
    rgba <span style=color:#f92672>=</span> cmap(iclust <span style=color:#f92672>/</span> (model<span style=color:#f92672>.</span>n_clusters<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>))    
    plt<span style=color:#f92672>.</span>plot(model<span style=color:#f92672>.</span>cluster_centers_[iclust,:], depth, marker<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;.&#39;</span>, color<span style=color:#f92672>=</span>rgba)
    
plt<span style=color:#f92672>.</span>gca()<span style=color:#f92672>.</span>invert_yaxis()  
plt<span style=color:#f92672>.</span>gca()<span style=color:#f92672>.</span>set_xlim([<span style=color:#f92672>-</span><span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>8</span>])
</code></pre></div><p><img src=/images/DasKmeans_files/DasKmeans_10_1.png alt=png></p><p>And we start to see a lot more variation. And since each of our profiles corresponds to a geographic coordinate, it&rsquo;s quite interesting to to map our profile categories back to their originating latitude and longitude. This results in neat category maps like this. For our 3 clusters, we get back a map that reflects our general understanding of the western US: slow velocities in the basin and range, faster velocities east of the Rockies:</p><p><img src=/images/DasKmeans_files/DasKmeans_7_0.png alt=png></p><p>At the higher cluster number, we get much more variation that reflects more local variations</p><p><img src=/images/DasKmeans_files/DasKmeans_11_0.png alt=png></p><h2 id=how-many-clusters>how many clusters?</h2><p>There&rsquo;s lots of interesting features in the above maps, relating to geologic history and current tectonic setting but I won&rsquo;t get into that here. Instead, the <strong>the question is how many clusters should we use?</strong> The answer is&mldr; it depends. From our two examples above, we see our coarse map returns broad variations (reflecting general tectonic setting) while our finer map incorporates local tectonic setting. So the &ldquo;correct&rdquo; number may depend on the feature you&rsquo;re interested in.</p><p>More mathematically, we can also consider the &ldquo;intertia&rdquo; parameter of our Kmeans calculation. The inertia is the sum-of-squares distance within each cluster (<a href=https://scikit-learn.org/stable/modules/clustering.html#k-means>see here for more</a>). As the number of clusters increases, the inertia value lowers (if you have too many, every data point will be its own cluster). So one approach is to re-calculate our fit for a range of clusters and investigate how the inertia value changes.</p><p>So to do this, let&rsquo;s first wrap our <code>TimeSeriesKMeans</code> call into a function for convenience:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>fit_a_model</span>(n_clust, data):
    model <span style=color:#f92672>=</span> TimeSeriesKMeans(n_clusters<span style=color:#f92672>=</span>n_clust, metric<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;euclidean&#34;</span>, max_iter<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)
    model<span style=color:#f92672>.</span>fit(dvsN)
    <span style=color:#66d9ef>return</span> model
</code></pre></div><p>And now we can calculate a model for a range of cluster numbers:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>%%</span>time
n_clusts <span style=color:#f92672>=</span> range(<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>50</span>)
models <span style=color:#f92672>=</span> []
<span style=color:#66d9ef>for</span> n_clust <span style=color:#f92672>in</span> n_clusts:
    models<span style=color:#f92672>.</span>append(fit_a_model(n_clust, dvsN))
</code></pre></div><p>This takes a bit of time, 3min 13s to be exact. And while the <code>TimeSeriesKMeans</code> docs indicate that you can parallelize the call with the <code>n_jobs</code> parameter, I didn&rsquo;t have any luck getting it to work. But given all my <a href=https://yt-project.github.io/blog/posts/dask_yt_pytep/>recent work with dask</a>, I figured it&rsquo;d be pretty easy to created a delayed workflow.</p><h2 id=a-daskdelayed-workflow-for-timeserieskmeans>a <code>dask.delayed</code> workflow for <code>TimeSeriesKMeans</code></h2><p>Because each of the calls to <code>TimeSeriesKMeans</code> is independent, we can simply create a bunch of <code>delayed</code> calls to <code>fit_a_model</code> and execute them in a batch-parallel workflow.</p><p>The first step is to spin up a client (using default parameters here):</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> dask.distributed <span style=color:#f92672>import</span> Client
<span style=color:#f92672>from</span> dask <span style=color:#f92672>import</span> delayed, compute

c <span style=color:#f92672>=</span> Client()
</code></pre></div><p>and then build our list of <code>delayed</code> objects:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>models <span style=color:#f92672>=</span> []
<span style=color:#66d9ef>for</span> n_clust <span style=color:#f92672>in</span> n_clusts:
    models<span style=color:#f92672>.</span>append(delayed(fit_a_model)(n_clust, dvsN))
</code></pre></div><p>Now when we simply call <code>compute</code>, and our separate calls to <code>TimeSeriesKMeans</code> will be sent to workers as they are available:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>%%</span>time
models <span style=color:#f92672>=</span> compute(<span style=color:#f92672>*</span>models)
</code></pre></div><p>It still takes a bit of time: 1min 24s on my laptop, but it is twice as fast as the plain python version! I&rsquo;ll probably keep playing with this to see if I can improve it further (I suspect there are more gains to be had here!), but it&rsquo;s not bad for very minimal coding effort.</p><h2 id=so-how-many-clusters>so: how many clusters?</h2><p>Returning to the question of how many clusters, let&rsquo;s pull out and plot the inertia vs number of clusters:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>inert <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([model<span style=color:#f92672>.</span>inertia_ <span style=color:#66d9ef>for</span> model <span style=color:#f92672>in</span> models])
nclust <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([model<span style=color:#f92672>.</span>n_clusters <span style=color:#66d9ef>for</span> model <span style=color:#f92672>in</span> models])
plt<span style=color:#f92672>.</span>plot(nclust, inert,<span style=color:#e6db74>&#39;k&#39;</span>,marker<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;.&#39;</span>)
plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;number of clusters&#39;</span>)
plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;model inertia&#39;</span>)
</code></pre></div><p><img src=/images/DasKmeans_files/DasKmeans_20_1.png alt=png></p><p>The inflection point in an inertia curve (the &ldquo;elbow&rdquo; criteria) is typically taken as a reasonable value. In this case, somewhere between 10-15 clusters. Of course, as said before, it depends a bit on the level of detail we&rsquo;re interested in, but it&rsquo;s unlikely that we would want to use more than 10-15 in our analysis.</p></div><div class=share-buttons><a class=twitter-share-button href=# title="Share on Twitter" data-url=https://chrishavlin.github.io/post/dask-kmeans/ data-text="Speeding up some K-means computation with dask"><i class="fab fa-twitter"></i></a><a class=linkedin-share-button href=# title="Share on LinkedIn" data-url=https://chrishavlin.github.io/post/dask-kmeans/ data-text="Speeding up some K-means computation with dask"><i class="fab fa-linkedin-in"></i></a><a class=facebook-share-button href=# title="Share on Facebook" data-url=https://chrishavlin.github.io/post/dask-kmeans/ data-text="Speeding up some K-means computation with dask"><i class="fab fa-facebook"></i></a><a class=telegram-share-button href=# title="Share on Telegram" data-url=https://chrishavlin.github.io/post/dask-kmeans/ data-text="Speeding up some K-means computation with dask"><i class="fab fa-telegram"></i></a><a class=pinterest-share-button href=# title="Share on Pinterest" data-url=https://chrishavlin.github.io/post/dask-kmeans/ data-text="Speeding up some K-means computation with dask"><i class="fab fa-pinterest"></i></a></div></div></main><footer><div><p>&copy; Chris Havlin 2022
&#183; <a href=https://creativecommons.org/licenses/by-sa/4.0 target=_blank>CC BY-SA 4.0</a>
&#183; Build with <a href=https://gohugo.io/ target=_blank>Hugo</a> & <a href=https://themes.gohugo.io/soho/ target=_blank>Soho</a> theme</p></div></footer><script src=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/js/all.min.js integrity="sha256-MAgcygDRahs+F/Nk5Vz387whB4kSK9NXlDN3w58LLq0=" crossorigin=anonymous></script><script src=/js/jquery.min.js></script><script src=/js/soho.js></script></body></html>